#' simple_dada
#'
#' Runs through the DADA2 routine with dynamic paramter
#' assignment. In situations where the data is clean this
#' will work well. If the data is not clean, it will be 
#' bet to either run the DADA2 routine. or each
#' sub-function.
#' 
#' @usage simple_dada(path)
#' @param path Directory for project. Raw reads should be 
#' contained in a sub-folder named raw_reads
#' @param cores The number of CPU cores/threads to use.
#' @import data.table
#' @import doParallel
#' @import parallel
#' @export
#' @return data.table

simple_dada <- function(path)

forward_files <- sort(list.files(file.path(path, 'raw_reads'), pattern = "_R1_001.fastq", full.names = TRUE))
reverse_files <- sort(list.files(file.path(path, 'raw_reads'), pattern = "_R2_001.fastq", full.names = TRUE))
fwd <- read_quality_report(forward_files, cores = 0)
rev <- read_quality_report(reverse_files, cores = 0)
fwd <- fwd[count > 0.1*median(count) & count < 5*median(count)]
rev <- rev[count > 0.1*median(count) & count < 5*median(count)]
if(cores == 1){
  out <- for(i in seq_along(fwd$sample)){
    filtered_f <- file.path(path, "filtered", paste0(fwd[i, 'sample'], "_F_filtered.fastq.gz"))
    filtered_r <- file.path(path, "filtered", paste0(rev[i, 'sample'], "_R_filtered.fastq.gz"))
    filterAndTrim(fwd[['file']][i], filtered_f, rev[['file']][i], filtered_r,
                  truncLen=c(fwd[['quality_length']][i], rev[['quality_length']][i]),
                  maxN = 0, maxEE = c(2,2), truncQ = 2, rm.phix = TRUE,
                  compress = TRUE, multithread = FALSE)
  }
} else {
  cl <- makeCluster(cores, type="FORK")  
  registerDoParallel(cl)
  out <- foreach(i = seq_along(fwd$sample), .combine = 'rbind') %dopar% {
    filtered_f <- file.path(path, "filtered", paste0(fwd[i, 'sample'], "_F_filtered.fastq.gz"))
    filtered_r <- file.path(path, "filtered", paste0(rev[i, 'sample'], "_R_filtered.fastq.gz"))
    filterAndTrim(fwd[['file']][i], filtered_f, rev[['file']][i], filtered_r,
                  truncLen=c(fwd[['quality_length']][i], rev[['quality_length']][i]),
                  maxN = 0, maxEE = c(2,2), truncQ = 2, rm.phix = TRUE,
                  compress = TRUE, multithread = FALSE)
  }
  stopCluster(cl)
}


filtered_f <- sort(list.files(file.path(path, 'filtered'), pattern = "_F_", full.names = TRUE))
filtered_r <- sort(list.files(file.path(path, 'filtered'), pattern = "_R_", full.names = TRUE))
errF <- learnErrors(filtered_f, randomize = TRUE, multithread = cores)
errR <- learnErrors(filtered_r, randomize = TRUE, multithread = cores)



sample.names <- sapply(strsplit(basename(filtered_f), "_"), `[`, 1)
dadas <- vector("list", length(sample.names))
names(dadas) <- sample.names
if(cores == 1){
  for(i in seq_along(dadas)){
    derep_forward <- derepFastq(filtered_f[i], verbose = FALSE)
    derep_reverse <- derepFastq(filtered_r[i], verbose = FALSE)
    dada_forward <- dada(derep_forward, err = errF, multithread = FALSE)
    dada_reverse <- dada(derep_reverse, err = errR, multithread = FALSE) 
    dadas[[i]] <-  mergePairs(dada_forward, derep_forward, 
                              dada_reverse, derep_reverse)
  }
} else {
  cl <- makeCluster(cores, type="FORK")  
  registerDoParallel(cl)
  dadas <- foreach(i = seq_along(dadas)) %dopar% {
    derep_forward <- derepFastq(filtered_f[i], verbose = FALSE)
    derep_reverse <- derepFastq(filtered_r[i], verbose = FALSE)
    dada_forward <- dada(derep_forward, err = errF, multithread = FALSE)
    dada_reverse <- dada(derep_reverse, err = errR, multithread = FALSE) 
    merged_reads <- mergePairs(dada_forward, derep_forward, 
                               dada_reverse, derep_reverse,
                               verbose = FALSE)
  }
  stopCluster(cl)
}

dir.create(file.path(path, 'dada2'), showWarnings = FALSE)
seq_table <- makeSequenceTable(dadas)
saveRDS(seq_table, file.path(path, 'dada2', 'seq_table.RDS'))
seq_table <- removeBimeraDenovo(seq_table, method="consensus", multithread=TRUE)
saveRDS(seq_table, file.path(path, 'dada2', 'seq_table.RDS'))
tax_table <- assignTaxonomy(seq_table, "/mnt/research/germs/databases/dada2/rdp_train_set_16.fa.gz", multithread=TRUE)
saveRDS(tax_table, file.path(path, 'dada2', 'tax_table.RDS'))

